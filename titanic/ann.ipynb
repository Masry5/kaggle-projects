{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures,StandardScaler,LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "x_test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19260\\2406982596.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19260\\2406982596.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n"
     ]
    }
   ],
   "source": [
    "data_cleaner=[df,x_test]\n",
    "for dataset in data_cleaner:    \n",
    "    #Discrete variables\n",
    "    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n",
    "\n",
    "    #quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split\n",
    "    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "#title_names = (df['Title'].value_counts() < 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_names=['Mr','Miss','Mrs','Master']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Title'] = df['Title'].apply(lambda x: 'Misc' if x not in title_names  else x)\n",
    "x_test['Title'] = x_test['Title'].apply(lambda x: 'Misc' if x not in title_names else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Master', 'Misc', 'Miss', 'Mr', 'Mrs'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      " 12  FamilySize   891 non-null    int64  \n",
      " 13  IsAlone      891 non-null    int64  \n",
      " 14  Title        891 non-null    object \n",
      "dtypes: float64(2), int64(7), object(6)\n",
      "memory usage: 104.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ids=x_test['PassengerId']\n",
    "\n",
    "df=df.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\n",
    "x_test=x_test.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\n",
    "\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode())\n",
    "\n",
    "x_test['Age'] = x_test['Age'].fillna(x_test['Age'].median())\n",
    "x_test['Fare'] = x_test['Fare'].fillna(x_test['Fare'].mean())\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_cols, prefix=categorical_cols,dtype=int)\n",
    "x_test = pd.get_dummies(x_test, columns=categorical_cols, prefix=categorical_cols,dtype=int)\n",
    "\n",
    "\n",
    "y_train=df['Survived']\n",
    "df=df.drop(['Survived'],axis=1)\n",
    "\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(df, y_train,test_size=0.20,random_state=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_train=y_train.to_numpy()\\ny_train.reshape(-1,1)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_train=y_train.to_numpy()\n",
    "y_train.reshape(-1,1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone',\n",
       "       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
       "       'Title_Master', 'Title_Misc', 'Title_Miss', 'Title_Mr', 'Title_Mrs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone',\n",
       "       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
       "       'Title_Master', 'Title_Misc', 'Title_Miss', 'Title_Mr', 'Title_Mrs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 5.2240 - accuracy: 0.5449 - val_loss: 1.3702 - val_accuracy: 0.6201\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.8182 - accuracy: 0.5393 - val_loss: 1.2937 - val_accuracy: 0.6927\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.7867 - accuracy: 0.5997 - val_loss: 1.1536 - val_accuracy: 0.7039\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.8287 - accuracy: 0.5997 - val_loss: 1.0170 - val_accuracy: 0.6927\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.9966 - accuracy: 0.6053 - val_loss: 0.9835 - val_accuracy: 0.6816\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.0025 - accuracy: 0.5969 - val_loss: 0.9528 - val_accuracy: 0.6816\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.4447 - accuracy: 0.6278 - val_loss: 0.8076 - val_accuracy: 0.6816\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.4048 - accuracy: 0.6067 - val_loss: 0.7134 - val_accuracy: 0.7039\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.2989 - accuracy: 0.6138 - val_loss: 0.6849 - val_accuracy: 0.7039\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0994 - accuracy: 0.6250 - val_loss: 0.6777 - val_accuracy: 0.6872\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0119 - accuracy: 0.6433 - val_loss: 0.6864 - val_accuracy: 0.6927\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9434 - accuracy: 0.6320 - val_loss: 0.6823 - val_accuracy: 0.6872\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9206 - accuracy: 0.6404 - val_loss: 0.6852 - val_accuracy: 0.6872\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.7985 - accuracy: 0.6615 - val_loss: 0.6765 - val_accuracy: 0.6816\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8735 - accuracy: 0.6503 - val_loss: 0.6718 - val_accuracy: 0.6816\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7913 - accuracy: 0.6362 - val_loss: 0.6608 - val_accuracy: 0.6816\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7589 - accuracy: 0.6278 - val_loss: 0.6494 - val_accuracy: 0.6704\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.6629 - val_loss: 0.6391 - val_accuracy: 0.6760\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7724 - accuracy: 0.6348 - val_loss: 0.6314 - val_accuracy: 0.6704\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7598 - accuracy: 0.6447 - val_loss: 0.6292 - val_accuracy: 0.6760\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.6348 - val_loss: 0.6315 - val_accuracy: 0.6816\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.6489 - val_loss: 0.6374 - val_accuracy: 0.6648\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.6601 - val_loss: 0.6320 - val_accuracy: 0.6704\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6489 - val_loss: 0.6326 - val_accuracy: 0.6592\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.6447 - val_loss: 0.6323 - val_accuracy: 0.6257\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.6433 - val_loss: 0.6347 - val_accuracy: 0.6089\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6503 - val_loss: 0.6327 - val_accuracy: 0.6034\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.6404 - val_loss: 0.6268 - val_accuracy: 0.6089\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.6545 - val_loss: 0.6290 - val_accuracy: 0.6034\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.6629 - val_loss: 0.6268 - val_accuracy: 0.6089\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6489 - val_loss: 0.6212 - val_accuracy: 0.6201\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6376 - val_loss: 0.6189 - val_accuracy: 0.6089\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6306 - val_loss: 0.6165 - val_accuracy: 0.6201\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.6629 - val_loss: 0.6161 - val_accuracy: 0.6145\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6587 - val_loss: 0.6099 - val_accuracy: 0.6089\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6433 - val_loss: 0.6123 - val_accuracy: 0.6145\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6573 - val_loss: 0.6118 - val_accuracy: 0.6089\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.6447 - val_loss: 0.6100 - val_accuracy: 0.6089\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6545 - val_loss: 0.6065 - val_accuracy: 0.6201\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6601 - val_loss: 0.6024 - val_accuracy: 0.6313\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.6685 - val_loss: 0.6017 - val_accuracy: 0.6257\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.6728 - val_loss: 0.6002 - val_accuracy: 0.6425\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6531 - val_loss: 0.5955 - val_accuracy: 0.6760\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6756 - val_loss: 0.5917 - val_accuracy: 0.6816\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.6756 - val_loss: 0.5906 - val_accuracy: 0.6816\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6643 - val_loss: 0.5965 - val_accuracy: 0.6704\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.6742 - val_loss: 0.5915 - val_accuracy: 0.6704\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6812 - val_loss: 0.5830 - val_accuracy: 0.6704\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.6615 - val_loss: 0.5800 - val_accuracy: 0.6983\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6629 - val_loss: 0.5813 - val_accuracy: 0.6816\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6854 - val_loss: 0.5734 - val_accuracy: 0.6927\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6994 - val_loss: 0.5780 - val_accuracy: 0.7095\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.6798 - val_loss: 0.5799 - val_accuracy: 0.6872\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6770 - val_loss: 0.5722 - val_accuracy: 0.6927\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.6713 - val_loss: 0.5934 - val_accuracy: 0.6704\n",
      "Epoch 56/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6952 - val_loss: 0.5761 - val_accuracy: 0.6760\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.6994 - val_loss: 0.5704 - val_accuracy: 0.6927\n",
      "Epoch 58/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.6868 - val_loss: 0.5626 - val_accuracy: 0.6927\n",
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6784 - val_loss: 0.5635 - val_accuracy: 0.6983\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.6770 - val_loss: 0.5626 - val_accuracy: 0.7095\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6840 - val_loss: 0.5697 - val_accuracy: 0.6983\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.6966 - val_loss: 0.5610 - val_accuracy: 0.7039\n",
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.6938 - val_loss: 0.5531 - val_accuracy: 0.7039\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.6671 - val_loss: 0.5474 - val_accuracy: 0.7039\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.6854 - val_loss: 0.5465 - val_accuracy: 0.7207\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.7149 - val_loss: 0.5481 - val_accuracy: 0.7095\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.6966 - val_loss: 0.5438 - val_accuracy: 0.7039\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.6882 - val_loss: 0.5519 - val_accuracy: 0.7263\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7093 - val_loss: 0.5470 - val_accuracy: 0.7542\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7079 - val_loss: 0.5449 - val_accuracy: 0.7374\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.6966 - val_loss: 0.5431 - val_accuracy: 0.7598\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.6868 - val_loss: 0.5398 - val_accuracy: 0.7318\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7022 - val_loss: 0.5322 - val_accuracy: 0.7709\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7360 - val_loss: 0.5289 - val_accuracy: 0.7654\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7163 - val_loss: 0.5367 - val_accuracy: 0.7765\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.6882 - val_loss: 0.5311 - val_accuracy: 0.7654\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.6910 - val_loss: 0.5376 - val_accuracy: 0.7542\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7191 - val_loss: 0.5261 - val_accuracy: 0.7709\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7346 - val_loss: 0.5249 - val_accuracy: 0.7765\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7261 - val_loss: 0.5262 - val_accuracy: 0.7821\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7163 - val_loss: 0.5343 - val_accuracy: 0.7765\n",
      "Epoch 82/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7486 - val_loss: 0.5301 - val_accuracy: 0.7765\n",
      "Epoch 83/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7556 - val_loss: 0.5174 - val_accuracy: 0.7821\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7388 - val_loss: 0.5145 - val_accuracy: 0.7765\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7725 - val_loss: 0.5114 - val_accuracy: 0.7821\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7486 - val_loss: 0.5144 - val_accuracy: 0.7877\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7416 - val_loss: 0.5172 - val_accuracy: 0.7821\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7486 - val_loss: 0.5164 - val_accuracy: 0.7877\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7640 - val_loss: 0.5107 - val_accuracy: 0.7877\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.7331 - val_loss: 0.5100 - val_accuracy: 0.7877\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7725 - val_loss: 0.5150 - val_accuracy: 0.7821\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7514 - val_loss: 0.5104 - val_accuracy: 0.7821\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7542 - val_loss: 0.5113 - val_accuracy: 0.7765\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7697 - val_loss: 0.5099 - val_accuracy: 0.7765\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7247 - val_loss: 0.5081 - val_accuracy: 0.7765\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7514 - val_loss: 0.5094 - val_accuracy: 0.7877\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7711 - val_loss: 0.5035 - val_accuracy: 0.7821\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7697 - val_loss: 0.5038 - val_accuracy: 0.7877\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7725 - val_loss: 0.5052 - val_accuracy: 0.7821\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7654 - val_loss: 0.5024 - val_accuracy: 0.7821\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7697 - val_loss: 0.5042 - val_accuracy: 0.7821\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7725 - val_loss: 0.5080 - val_accuracy: 0.7654\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7458 - val_loss: 0.5027 - val_accuracy: 0.7765\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7669 - val_loss: 0.5044 - val_accuracy: 0.7821\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7753 - val_loss: 0.5009 - val_accuracy: 0.7765\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7781 - val_loss: 0.5113 - val_accuracy: 0.7765\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7711 - val_loss: 0.5055 - val_accuracy: 0.7709\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7697 - val_loss: 0.5050 - val_accuracy: 0.7765\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7823 - val_loss: 0.4992 - val_accuracy: 0.7765\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7781 - val_loss: 0.5005 - val_accuracy: 0.7765\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7949 - val_loss: 0.4967 - val_accuracy: 0.7821\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7935 - val_loss: 0.4939 - val_accuracy: 0.7821\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7795 - val_loss: 0.4910 - val_accuracy: 0.7765\n",
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7753 - val_loss: 0.4879 - val_accuracy: 0.7765\n",
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7781 - val_loss: 0.4901 - val_accuracy: 0.7765\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7709\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7528 - val_loss: 0.4945 - val_accuracy: 0.7765\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7697 - val_loss: 0.4915 - val_accuracy: 0.7709\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7781 - val_loss: 0.4934 - val_accuracy: 0.7765\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8020 - val_loss: 0.4909 - val_accuracy: 0.7765\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.8090 - val_loss: 0.4870 - val_accuracy: 0.7765\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7921 - val_loss: 0.4875 - val_accuracy: 0.7654\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7893 - val_loss: 0.4861 - val_accuracy: 0.7654\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7851 - val_loss: 0.4866 - val_accuracy: 0.7654\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8062 - val_loss: 0.4854 - val_accuracy: 0.7654\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8006 - val_loss: 0.4840 - val_accuracy: 0.7654\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8132 - val_loss: 0.4847 - val_accuracy: 0.7654\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.8034 - val_loss: 0.4801 - val_accuracy: 0.7654\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7907 - val_loss: 0.4819 - val_accuracy: 0.7654\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7963 - val_loss: 0.4807 - val_accuracy: 0.7654\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7907 - val_loss: 0.4853 - val_accuracy: 0.7765\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7949 - val_loss: 0.4802 - val_accuracy: 0.7654\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7879 - val_loss: 0.4806 - val_accuracy: 0.7654\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7725 - val_loss: 0.4837 - val_accuracy: 0.7821\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7992 - val_loss: 0.4802 - val_accuracy: 0.7765\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8006 - val_loss: 0.4762 - val_accuracy: 0.7709\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.8034 - val_loss: 0.4757 - val_accuracy: 0.7709\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7978 - val_loss: 0.4738 - val_accuracy: 0.7709\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7921 - val_loss: 0.4772 - val_accuracy: 0.7765\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7992 - val_loss: 0.4736 - val_accuracy: 0.7709\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.8062 - val_loss: 0.4746 - val_accuracy: 0.7654\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7949 - val_loss: 0.4725 - val_accuracy: 0.7765\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.8020 - val_loss: 0.4736 - val_accuracy: 0.7821\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8132 - val_loss: 0.4705 - val_accuracy: 0.7709\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.8020 - val_loss: 0.4718 - val_accuracy: 0.7709\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7935 - val_loss: 0.4703 - val_accuracy: 0.7765\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8118 - val_loss: 0.4689 - val_accuracy: 0.7765\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8132 - val_loss: 0.4677 - val_accuracy: 0.7709\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.8118 - val_loss: 0.4665 - val_accuracy: 0.7709\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8174 - val_loss: 0.4637 - val_accuracy: 0.7709\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8118 - val_loss: 0.4684 - val_accuracy: 0.7821\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.8006 - val_loss: 0.4677 - val_accuracy: 0.7877\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8258 - val_loss: 0.4658 - val_accuracy: 0.7709\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.8160 - val_loss: 0.4648 - val_accuracy: 0.7765\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8118 - val_loss: 0.4621 - val_accuracy: 0.7765\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8048 - val_loss: 0.4621 - val_accuracy: 0.7765\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.8244 - val_loss: 0.4675 - val_accuracy: 0.7765\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.8301 - val_loss: 0.4647 - val_accuracy: 0.7765\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8202 - val_loss: 0.4649 - val_accuracy: 0.7821\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8104 - val_loss: 0.4610 - val_accuracy: 0.7709\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8118 - val_loss: 0.4588 - val_accuracy: 0.7765\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.8216 - val_loss: 0.4587 - val_accuracy: 0.7765\n",
      "Epoch 163/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8118 - val_loss: 0.4654 - val_accuracy: 0.7821\n",
      "Epoch 164/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8230 - val_loss: 0.4545 - val_accuracy: 0.7821\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8244 - val_loss: 0.4617 - val_accuracy: 0.7877\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.8202 - val_loss: 0.4550 - val_accuracy: 0.7765\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8104 - val_loss: 0.4576 - val_accuracy: 0.7989\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.8034 - val_loss: 0.4544 - val_accuracy: 0.7989\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8118 - val_loss: 0.4578 - val_accuracy: 0.7821\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7963 - val_loss: 0.4571 - val_accuracy: 0.7877\n",
      "Epoch 171/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.8188 - val_loss: 0.4575 - val_accuracy: 0.7933\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.8160 - val_loss: 0.4561 - val_accuracy: 0.7821\n",
      "Epoch 173/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8188 - val_loss: 0.4558 - val_accuracy: 0.7765\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8244 - val_loss: 0.4543 - val_accuracy: 0.7821\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.8062 - val_loss: 0.4543 - val_accuracy: 0.7821\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8258 - val_loss: 0.4535 - val_accuracy: 0.7821\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8272 - val_loss: 0.4537 - val_accuracy: 0.7933\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8188 - val_loss: 0.4537 - val_accuracy: 0.7765\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.8174 - val_loss: 0.4542 - val_accuracy: 0.7765\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.8076 - val_loss: 0.4537 - val_accuracy: 0.7933\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8399 - val_loss: 0.4573 - val_accuracy: 0.7877\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8146 - val_loss: 0.4570 - val_accuracy: 0.7765\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8258 - val_loss: 0.4535 - val_accuracy: 0.7821\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.8188 - val_loss: 0.4548 - val_accuracy: 0.7877\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8216 - val_loss: 0.4514 - val_accuracy: 0.7821\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8132 - val_loss: 0.4502 - val_accuracy: 0.7877\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8329 - val_loss: 0.4531 - val_accuracy: 0.8101\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8343 - val_loss: 0.4514 - val_accuracy: 0.7933\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8216 - val_loss: 0.4480 - val_accuracy: 0.8101\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8329 - val_loss: 0.4512 - val_accuracy: 0.7989\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8343 - val_loss: 0.4579 - val_accuracy: 0.8324\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.8202 - val_loss: 0.4548 - val_accuracy: 0.7765\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8357 - val_loss: 0.4505 - val_accuracy: 0.7821\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8371 - val_loss: 0.4536 - val_accuracy: 0.7877\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8258 - val_loss: 0.4496 - val_accuracy: 0.7877\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8399 - val_loss: 0.4501 - val_accuracy: 0.8101\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8357 - val_loss: 0.4519 - val_accuracy: 0.7989\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8287 - val_loss: 0.4516 - val_accuracy: 0.8045\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8371 - val_loss: 0.4559 - val_accuracy: 0.8045\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8371 - val_loss: 0.4560 - val_accuracy: 0.7933\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8202 - val_loss: 0.4533 - val_accuracy: 0.7821\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8301 - val_loss: 0.4538 - val_accuracy: 0.7821\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8441 - val_loss: 0.4537 - val_accuracy: 0.7821\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8244 - val_loss: 0.4544 - val_accuracy: 0.7821\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8287 - val_loss: 0.4529 - val_accuracy: 0.7821\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8188 - val_loss: 0.4527 - val_accuracy: 0.8045\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8371 - val_loss: 0.4530 - val_accuracy: 0.8101\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8357 - val_loss: 0.4554 - val_accuracy: 0.8156\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8230 - val_loss: 0.4547 - val_accuracy: 0.8156\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8371 - val_loss: 0.4524 - val_accuracy: 0.8156\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8287 - val_loss: 0.4589 - val_accuracy: 0.7933\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.8287 - val_loss: 0.4561 - val_accuracy: 0.7933\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8287 - val_loss: 0.4575 - val_accuracy: 0.8156\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8371 - val_loss: 0.4558 - val_accuracy: 0.7877\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8315 - val_loss: 0.4560 - val_accuracy: 0.7989\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8216 - val_loss: 0.4567 - val_accuracy: 0.8045\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8329 - val_loss: 0.4540 - val_accuracy: 0.8101\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8315 - val_loss: 0.4527 - val_accuracy: 0.8101\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8287 - val_loss: 0.4532 - val_accuracy: 0.8045\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8272 - val_loss: 0.4541 - val_accuracy: 0.7989\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8301 - val_loss: 0.4528 - val_accuracy: 0.8101\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8287 - val_loss: 0.4568 - val_accuracy: 0.8101\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8216 - val_loss: 0.4605 - val_accuracy: 0.8045\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8174 - val_loss: 0.4568 - val_accuracy: 0.8156\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8329 - val_loss: 0.4595 - val_accuracy: 0.8212\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8287 - val_loss: 0.4623 - val_accuracy: 0.8212\n",
      "Epoch 227/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8258 - val_loss: 0.4585 - val_accuracy: 0.8212\n",
      "Epoch 228/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8216 - val_loss: 0.4613 - val_accuracy: 0.8268\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8202 - val_loss: 0.4578 - val_accuracy: 0.8212\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8385 - val_loss: 0.4598 - val_accuracy: 0.8156\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8258 - val_loss: 0.4572 - val_accuracy: 0.8212\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8258 - val_loss: 0.4553 - val_accuracy: 0.8212\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8357 - val_loss: 0.4567 - val_accuracy: 0.8212\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8399 - val_loss: 0.4609 - val_accuracy: 0.8156\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8301 - val_loss: 0.4601 - val_accuracy: 0.8101\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8202 - val_loss: 0.4576 - val_accuracy: 0.8156\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8272 - val_loss: 0.4608 - val_accuracy: 0.7989\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8258 - val_loss: 0.4574 - val_accuracy: 0.7877\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8357 - val_loss: 0.4577 - val_accuracy: 0.8156\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(64,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "# Specify early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=500, batch_size=32,\n",
    "                    validation_data=(x_cv, y_cv), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best weights from the model\n",
    "best_weights = model.get_weights()\n",
    "\n",
    "# Reset the model to its initial weights\n",
    "model.reset_states()\n",
    "\n",
    "# Set the best weights to the model\n",
    "model.set_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.8101\n",
      "[0.4479576349258423, 0.8100558519363403]\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3935 - accuracy: 0.8385\n",
      "[0.3934500217437744, 0.8384831547737122]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x_cv,y_cv))\n",
    "print(model.evaluate(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 999us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(x_train)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i]>0.5:\n",
    "        predictions[i]=1\n",
    "    else:\n",
    "        predictions[i]=0\n",
    "        \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_train, predictions)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "class_names = [str(i) for i in range(2)]  \n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAK9CAYAAAADlCV3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArf0lEQVR4nO3de5RVdf3/8ddwG5C7oKB+FRISMS94y9QE+Ym3vPM1MzMBM7XQTMS8lAmY8v2qiJIXLFOJtLRMM7W8oZlGaiqCZiZeqq+KchGQi6DM+f3hYmoElEFgPurjsdas5XzOPnu/91ms6dmefc5UVSqVSgAAoECNGnoAAABYEbEKAECxxCoAAMUSqwAAFEusAgBQLLEKAECxxCoAAMUSqwAAFEusAgBQLLEKsBzPPfdc9tprr7Rt2zZVVVW55ZZbVuv+X3rppVRVVeXaa69drfv9KNt9992z++67N/QYQGHEKlCs559/Pscdd1w23XTTNG/ePG3atMmuu+6aSy65JAsXLlyjxx4wYECmTJmSc889N+PHj88OO+ywRo+3Ng0cODBVVVVp06bNcl/H5557LlVVVamqqsqFF15Y7/2/8sorGTZsWCZNmrQapgU+6Zo09AAAy3P77bfni1/8Yqqrq3PUUUdlyy23zOLFi/Pggw/m1FNPzdNPP50f/ehHa+TYCxcuzMSJE/Pd7343J5xwwho5RpcuXbJw4cI0bdp0jez/gzRp0iQLFizIb3/72xx22GF1HrvuuuvSvHnzvPXWW6u071deeSXDhw9P165d06tXr5V+3l133bVKxwM+3sQqUJwXX3wxhx9+eLp06ZIJEyZkgw02qH1s8ODBmTp1am6//fY1dvzp06cnSdq1a7fGjlFVVZXmzZuvsf1/kOrq6uy66675+c9/vkysXn/99dlvv/1y0003rZVZFixYkHXWWSfNmjVbK8cDPlrcBgAU5/zzz8+8efPyk5/8pE6oLtW9e/ecdNJJtd+/8847Oeecc9KtW7dUV1ena9euOfPMM7No0aI6z+vatWv233//PPjgg/nsZz+b5s2bZ9NNN81Pf/rT2m2GDRuWLl26JElOPfXUVFVVpWvXrkne/fX50v/+T8OGDUtVVVWdtbvvvjuf//zn065du7Rq1So9evTImWeeWfv4iu5ZnTBhQnbbbbe0bNky7dq1y0EHHZRnnnlmucebOnVqBg4cmHbt2qVt27YZNGhQFixYsOIX9j2OOOKI/O53v8vs2bNr1x599NE899xzOeKII5bZftasWRk6dGi22mqrtGrVKm3atMm+++6bJ598snab+++/PzvuuGOSZNCgQbW3Eyw9z9133z1bbrllHnvssfTu3TvrrLNO7evy3ntWBwwYkObNmy9z/nvvvXfat2+fV155ZaXPFfjoEqtAcX77299m0003zS677LJS2x9zzDH5/ve/n+222y6jR49Onz59MnLkyBx++OHLbDt16tQceuih2XPPPTNq1Ki0b98+AwcOzNNPP50k6d+/f0aPHp0k+fKXv5zx48fn4osvrtf8Tz/9dPbff/8sWrQoI0aMyKhRo3LggQfmoYceet/n3XPPPdl7773z+uuvZ9iwYRkyZEj+9Kc/Zdddd81LL720zPaHHXZY3nzzzYwcOTKHHXZYrr322gwfPnyl5+zfv3+qqqry61//unbt+uuvz+abb57ttttume1feOGF3HLLLdl///1z0UUX5dRTT82UKVPSp0+f2nDs2bNnRowYkSQ59thjM378+IwfPz69e/eu3c/MmTOz7777plevXrn44ovTt2/f5c53ySWXZL311suAAQOyZMmSJMmVV16Zu+66Kz/84Q+z4YYbrvS5Ah9hFYCCzJkzp5KkctBBB63U9pMmTaokqRxzzDF11ocOHVpJUpkwYULtWpcuXSpJKg888EDt2uuvv16prq6unHLKKbVrL774YiVJ5YILLqizzwEDBlS6dOmyzAxnn3125T9/nI4ePbqSpDJ9+vQVzr30GNdcc03tWq9evSrrr79+ZebMmbVrTz75ZKVRo0aVo446apnjHX300XX2ecghh1Q6dOiwwmP+53m0bNmyUqlUKoceemhljz32qFQqlcqSJUsqnTt3rgwfPny5r8Fbb71VWbJkyTLnUV1dXRkxYkTt2qOPPrrMuS3Vp0+fSpLK2LFjl/tYnz596qzdeeedlSSVH/zgB5UXXnih0qpVq8rBBx/8gecIfHy4sgoUZe7cuUmS1q1br9T2d9xxR5JkyJAhddZPOeWUJFnm3tYtttgiu+22W+336623Xnr06JEXXnhhlWd+r6X3uv7mN79JTU3NSj3n1VdfzaRJkzJw4MCsu+66tetbb7119txzz9rz/E/HH398ne932223zJw5s/Y1XBlHHHFE7r///kybNi0TJkzItGnTlnsLQPLufa6NGr37PxtLlizJzJkza29xePzxx1f6mNXV1Rk0aNBKbbvXXnvluOOOy4gRI9K/f/80b948V1555UofC/joE6tAUdq0aZMkefPNN1dq+3/84x9p1KhRunfvXme9c+fOadeuXf7xj3/UWd9kk02W2Uf79u3zxhtvrOLEy/rSl76UXXfdNcccc0w6deqUww8/PDfeeOP7huvSOXv06LHMYz179syMGTMyf/78OuvvPZf27dsnSb3O5Qtf+EJat26dG264Idddd1123HHHZV7LpWpqajJ69Oh8+tOfTnV1dTp27Jj11lsvkydPzpw5c1b6mBtttFG93kx14YUXZt11182kSZMyZsyYrL/++iv9XOCjT6wCRWnTpk023HDDPPXUU/V63nvf4LQijRs3Xu56pVJZ5WMsvZ9yqRYtWuSBBx7IPffck69+9auZPHlyvvSlL2XPPfdcZtsP48Ocy1LV1dXp379/xo0bl5tvvnmFV1WT5LzzzsuQIUPSu3fv/OxnP8udd96Zu+++O5/5zGdW+gpy8u7rUx9PPPFEXn/99STJlClT6vVc4KNPrALF2X///fP8889n4sSJH7htly5dUlNTk+eee67O+muvvZbZs2fXvrN/dWjfvn2dd84v9d6rt0nSqFGj7LHHHrnooovy17/+Neeee24mTJiQ++67b7n7Xjrns88+u8xjf/vb39KxY8e0bNnyw53AChxxxBF54okn8uabby73TWlL/epXv0rfvn3zk5/8JIcffnj22muv9OvXb5nXZGX/j8PKmD9/fgYNGpQtttgixx57bM4///w8+uijq23/QPnEKlCc73znO2nZsmWOOeaYvPbaa8s8/vzzz+eSSy5J8u6vsZMs8479iy66KEmy3377rba5unXrljlz5mTy5Mm1a6+++mpuvvnmOtvNmjVrmecu/XD8936c1lIbbLBBevXqlXHjxtWJv6eeeip33XVX7XmuCX379s0555yTSy+9NJ07d17hdo0bN17mqu0vf/nLvPzyy3XWlkb18sK+vk477bT885//zLhx43LRRRela9euGTBgwApfR+Djxx8FAIrTrVu3XH/99fnSl76Unj171vkLVn/605/yy1/+MgMHDkySbLPNNhkwYEB+9KMfZfbs2enTp08eeeSRjBs3LgcffPAKPxZpVRx++OE57bTTcsghh+Rb3/pWFixYkCuuuCKbbbZZnTcYjRgxIg888ED222+/dOnSJa+//nouv/zy/Nd//Vc+//nPr3D/F1xwQfbdd9/svPPO+drXvpaFCxfmhz/8Ydq2bZthw4attvN4r0aNGuV73/veB263//77Z8SIERk0aFB22WWXTJkyJdddd1023XTTOtt169Yt7dq1y9ixY9O6deu0bNkyO+20Uz71qU/Va64JEybk8ssvz9lnn137UVrXXHNNdt9995x11lk5//zz67U/4KPJlVWgSAceeGAmT56cQw89NL/5zW8yePDgnH766XnppZcyatSojBkzpnbbq666KsOHD8+jjz6ab3/725kwYULOOOOM/OIXv1itM3Xo0CE333xz1llnnXznO9/JuHHjMnLkyBxwwAHLzL7JJpvk6quvzuDBg3PZZZeld+/emTBhQtq2bbvC/ffr1y+///3v06FDh3z/+9/PhRdemM997nN56KGH6h16a8KZZ56ZU045JXfeeWdOOumkPP7447n99tuz8cYb19muadOmGTduXBo3bpzjjz8+X/7yl/OHP/yhXsd68803c/TRR2fbbbfNd7/73dr13XbbLSeddFJGjRqVP//5z6vlvICyVVXqcyc+AACsRa6sAgBQLLEKAECxxCoAAMUSqwAAFEusAgBQLLEKAECxxCoAAMX6WP4FqxbbntDQIwCsVm88emlDjwCwWjVfyQp1ZRUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAolliF99h1u2751cXH5YW7zs3CJy7NAbtvvcw2Z31jv7xw17mZNfGi3D72hHTbZL06j3ffZP3cOPrY/GvC/+S1P16Qe68+Ob13+PTaOgWAVfKL66/Lvnv+v+y47Vb5yuFfzJTJkxt6JBCr8F4tW1Rnyt9fzrdH3rDcx08Z2C/f/HKffOu8X6T3URdm/sLF+e1lg1PdrEntNr8ec3yaNG6UfY8bk12+cn4m//3l/HrM8enUofXaOg2Aevn97+7IheePzHHfHJxf/PLm9Oixeb5x3Ncyc+bMhh6NTzixCu9x10N/zfDLb8ut9y3/isLgI/rmf398Z267f0qeeu6VHHPWT7PBem1zYN9tkiQd2rXMp7usn1HX3J2nnnslz/9zes4a85u0bFGdLbpvuDZPBWCljR93TfofelgOPuS/061793zv7OFp3rx5bvn1TQ09Gp9wYhXqoetGHbLBem0z4eG/1a7NnfdWHn3qpey0ddckyczZ8/Psi9NyxP6fzTrNm6Vx40Y55r8/n9dmzs0Tf/1nA00OsGJvL16cZ/76dD638y61a40aNcrnPrdLJj/5RANOBkmTD95kzZkxY0auvvrqTJw4MdOmTUuSdO7cObvssksGDhyY9dZb7wP2AGtX545tkiSvz3qzzvrrM99Mpw5tar/f7/hLc8PoYzP9oQtTU1PJ9Dfm5aDBl2f2mwvX6rwAK+ON2W9kyZIl6dChQ531Dh065MUXX2igqeBdDXZl9dFHH81mm22WMWPGpG3btundu3d69+6dtm3bZsyYMdl8883zl7/85QP3s2jRosydO7fOV6VmyVo4A1ix0Wcclumz3ky/oy/Obl+9ILfe92RuuuS42tgFAFZOg11ZPfHEE/PFL34xY8eOTVVVVZ3HKpVKjj/++Jx44omZOHHi++5n5MiRGT58eJ21xp12TNMNPrvaZ4ZpM+YmSdZft3XtfyfJ+h1aZ/Kz/5ck2f2zm+ULu22ZDfp8J2/OfytJ8u2RN2aPz22eIw/YKRdec/faHxzgfbRv1z6NGzde5s1UM2fOTMeOHRtoKnhXg11ZffLJJ3PyyScvE6pJUlVVlZNPPjmTJk36wP2cccYZmTNnTp2vJp22XwMTQ/LSyzPz6vQ56btTj9q11i2bZ8ctu+bhyS8lSdZp3ixJUlNTU+e5NTWV5f57B2hoTZs1S88tPpOH//zvC0Q1NTV5+OGJ2XqbbRtwMmjAK6udO3fOI488ks0333y5jz/yyCPp1KnTB+6nuro61dXVddaqGjVeLTPyydSyRbN02/jf90t33ahDtt5so7wxd0H+Ne2NXHb9fTntmH0y9Z/T89LLM3P2N/fLq9Pn5Nb7nkySPDz5xbwxd0GuOueonPej32XhW2/n6P67pOtGHfL7B59uqNMCeF9fHTAoZ515Wj7zmS2z5VZb52fjx2XhwoU5+JD+DT0an3ANFqtDhw7Nsccem8ceeyx77LFHbZi+9tpruffee/PjH/84F154YUONxyfYdlt0yV1XnVT7/flD/ztJMv7WP+fYs3+WUdfek3VaVOfS73057Vq3yJ8mPZ8DB1+eRYvfSfLupwEcdMLlGTb4gPzuym+laZNGeeaFafniyT/KlL+/3CDnBPBB9tn3C3lj1qxcfumYzJgxPT0275nLr7wqHdwGQAOrqlQqlYY6+A033JDRo0fnsccey5Il774pqnHjxtl+++0zZMiQHHbYYau03xbbnrA6xwRocG88emlDjwCwWjVfyUumDRqrS7399tuZMWNGkqRjx45p2rTph9qfWAU+bsQq8HGzsrHaoJ+zulTTpk2zwQYbNPQYAAAUxl+wAgCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBirVKs/vGPf8yRRx6ZnXfeOS+//HKSZPz48XnwwQdX63AAAHyy1TtWb7rppuy9995p0aJFnnjiiSxatChJMmfOnJx33nmrfUAAAD656h2rP/jBDzJ27Nj8+Mc/TtOmTWvXd9111zz++OOrdTgAAD7Z6h2rzz77bHr37r3Metu2bTN79uzVMRMAACRZhVjt3Llzpk6dusz6gw8+mE033XS1DAUAAMkqxOrXv/71nHTSSXn44YdTVVWVV155Jdddd12GDh2ab3zjG2tiRgAAPqGa1PcJp59+empqarLHHntkwYIF6d27d6qrqzN06NCceOKJa2JGAAA+oaoqlUplVZ64ePHiTJ06NfPmzcsWW2yRVq1are7ZVlmLbU9o6BEAVqs3Hr20oUcAWK2ar+Ql03pfWV2qWbNm2WKLLVb16QAA8IHqHat9+/ZNVVXVCh+fMGHChxoIAACWqnes9urVq873b7/9diZNmpSnnnoqAwYMWF1zAQBA/WN19OjRy10fNmxY5s2b96EHAgCAper90VUrcuSRR+bqq69eXbsDAIBVf4PVe02cODHNmzdfXbv7ULb98mENPQIAAKtBvWO1f//+db6vVCp59dVX85e//CVnnXXWahsMAADqHatt27at832jRo3So0ePjBgxInvttddqGwwAAOoVq0uWLMmgQYOy1VZbpX379mtqJgAASFLPN1g1btw4e+21V2bPnr2GxgEAgH+r96cBbLnllnnhhRfWxCwAAFBHvWP1Bz/4QYYOHZrbbrstr776aubOnVvnCwAAVpeVvmd1xIgROeWUU/KFL3whSXLggQfW+bOrlUolVVVVWbJkyeqfEgCAT6SVjtXhw4fn+OOPz3333bcm5wEAgForHauVSiVJ0qdPnzU2DAAA/Kd63bP6n7/2BwCANa1en7O62WabfWCwzpo160MNBAAAS9UrVocPH77MX7ACAIA1pV6xevjhh2f99ddfU7MAAEAdK33PqvtVAQBY21Y6Vpd+GgAAAKwtK30bQE1NzZqcAwAAllHvP7cKAABri1gFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGKJVQAAiiVWAQAollgFAKBYYhUAgGI1aegBoHQ3HffZbNC2+bLrj7+SUfdMzUHbdM6ePddPj06t0rK6Sfa65KHMW7SkASYF+HB+cf11GXfNTzJjxvRs1mPznH7mWdlq660beiw+4cQqfICv/fSJNPqP30Fs2rFlxnxp60x4dnqSpLpJ4zz84ht5+MU38o0+n2qgKQE+nN//7o5ceP7IfO/s4dlqq21y3fhx+cZxX8tvbvt9OnTo0NDj8QnmNgD4ALMXvp1Z8//9tWu3dfN/byzME/+akyS58bGXM/7hf+WpV+Y28KQAq278uGvS/9DDcvAh/51u3bvne2cPT/PmzXPLr29q6NH4hBOrUA9NGlVl7y065bYp0xp6FIDV5u3Fi/PMX5/O53bepXatUaNG+dzndsnkJ59owMlArEK99P50h7Rq3iR3PPVaQ48CsNq8MfuNLFmyZJlf93fo0CEzZsxooKngXUXH6r/+9a8cffTR77vNokWLMnfu3DpfNe8sXksT8klzwNad8+cXZmXGPP/GAGBtKDpWZ82alXHjxr3vNiNHjkzbtm3rfL1833VraUI+STq3qc4OXdrnt5PdAgB8vLRv1z6NGzfOzJkz66zPnDkzHTt2bKCp4F0N+mkAt9566/s+/sILL3zgPs4444wMGTKkztpelz7yoeaC5dlvq855Y8Hi/On5mR+8McBHSNNmzdJzi8/k4T9PzP/bo1+SpKamJg8/PDGHf/nIBp6OT7oGjdWDDz44VVVVqVQqK9ymqqrqffdRXV2d6urqOmuNmjRbLfPBUlVJ9tuyU3731GtZ8p5/ruu2bJoOLZvlv9q3SJJ0W69lFixekmlzF+XNt95Z+8MCrIKvDhiUs848LZ/5zJbZcqut87Px47Jw4cIcfEj/hh6NT7gGjdUNNtggl19+eQ466KDlPj5p0qRsv/32a3kqWNaOXdunc9vmuW3Ksm+sOqTXhvnarl1qv7/iiF5Jkh/c8aw3YgEfGfvs+4W8MWtWLr90TGbMmJ4em/fM5VdelQ5uA6CBVVXe77LmGnbggQemV69eGTFixHIff/LJJ7PtttumpqamXvvd5fwHVsd4AMWYMKR3Q48AsFo1X8lLpg16ZfXUU0/N/PnzV/h49+7dc999963FiQAAKEmDxupuu+32vo+3bNkyffr0WUvTAABQmqI/ugoAgE82sQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxaqqVCqVhh4CPooWLVqUkSNH5owzzkh1dXVDjwPwofm5RonEKqyiuXPnpm3btpkzZ07atGnT0OMAfGh+rlEitwEAAFAssQoAQLHEKgAAxRKrsIqqq6tz9tlnexMC8LHh5xol8gYrAACK5coqAADFEqsAABRLrAIAUCyxCgBAscQqrKLLLrssXbt2TfPmzbPTTjvlkUceaeiRAFbJAw88kAMOOCAbbrhhqqqqcssttzT0SFBLrMIquOGGGzJkyJCcffbZefzxx7PNNttk7733zuuvv97QowHU2/z587PNNtvksssua+hRYBk+ugpWwU477ZQdd9wxl156aZKkpqYmG2+8cU488cScfvrpDTwdwKqrqqrKzTffnIMPPrihR4EkrqxCvS1evDiPPfZY+vXrV7vWqFGj9OvXLxMnTmzAyQDg40esQj3NmDEjS5YsSadOneqsd+rUKdOmTWugqQDg40msAgBQLLEK9dSxY8c0btw4r732Wp311157LZ07d26gqQDg40msQj01a9Ys22+/fe69997atZqamtx7773ZeeedG3AyAPj4adLQA8BH0ZAhQzJgwIDssMMO+exnP5uLL7448+fPz6BBgxp6NIB6mzdvXqZOnVr7/YsvvphJkyZl3XXXzSabbNKAk4GProJVdumll+aCCy7ItGnT0qtXr4wZMyY77bRTQ48FUG/3339/+vbtu8z6gAEDcu211679geA/iFUAAIrlnlUAAIolVgEAKJZYBQCgWGIVAIBiiVUAAIolVgEAKJZYBQCgWGIVAIBiiVWAwgwcODAHH3xw7fe77757vv3tb6/1Oe6///5UVVVl9uzZa/3YAEuJVYCVNHDgwFRVVaWqqirNmjVL9+7dM2LEiLzzzjtr9Li//vWvc84556zUtgIT+Lhp0tADAHyU7LPPPrnmmmuyaNGi3HHHHRk8eHCaNm2aM844o852ixcvTrNmzVbLMdddd93Vsh+AjyJXVgHqobq6Op07d06XLl3yjW98I/369cutt95a+6v7c889NxtuuGF69OiRJPnXv/6Vww47LO3atcu6666bgw46KC+99FLt/pYsWZIhQ4akXbt26dChQ77zne+kUqnUOeZ7bwNYtGhRTjvttGy88caprq5O9+7d85Of/CQvvfRS+vbtmyRp3759qqqqMnDgwCRJTU1NRo4cmU996lNp0aJFttlmm/zqV7+qc5w77rgjm222WVq0aJG+ffvWmROgoYhVgA+hRYsWWbx4cZLk3nvvzbPPPpu77747t912W95+++3svffead26df74xz/moYceSqtWrbLPPvvUPmfUqFG59tprc/XVV+fBBx/MrFmzcvPNN7/vMY866qj8/Oc/z5gxY/LMM8/kyiuvTKtWrbLxxhvnpptuSpI8++yzefXVV3PJJZckSUaOHJmf/vSnGTt2bJ5++umcfPLJOfLII/OHP/whybtR3b9//xxwwAGZNGlSjjnmmJx++ulr6mUDWGluAwBYBZVKJffee2/uvPPOnHjiiZk+fXpatmyZq666qvbX/z/72c9SU1OTq666KlVVVUmSa665Ju3atcv999+fvfbaKxdffHHOOOOM9O/fP0kyduzY3HnnnSs87t///vfceOONufvuu9OvX78kyaabblr7+NJbBtZff/20a9cuybtXYs8777zcc8892XnnnWuf8+CDD+bKK69Mnz59csUVV6Rbt24ZNWpUkqRHjx6ZMmVK/vd//3c1vmoA9SdWAerhtttuS6tWrfL222+npqYmRxxxRIYNG5bBgwdnq622qnOf6pNPPpmpU6emdevWdfbx1ltv5fnnn8+cOXPy6quvZqeddqp9rEmTJtlhhx2WuRVgqUmTJqVx48bp06fPSs88derULFiwIHvuuWed9cWLF2fbbbdNkjzzzDN15khSG7YADUmsAtRD3759c8UVV6RZs2bZcMMN06TJv3+MtmzZss628+bNy/bbb5/rrrtumf2st956q3T8Fi1a1Ps58+bNS5Lcfvvt2Wijjeo8Vl1dvUpzAKwtYhWgHlq2bJnu3buv1Lbbbbddbrjhhqy//vpp06bNcrfZYIMN8vDDD6d3795JknfeeSePPfZYtttuu+Vuv9VWW6WmpiZ/+MMfam8D+E9Lr+wuWbKkdm2LLbZIdXV1/vnPf67wimzPnj1z66231ln785///MEnCbCGeYMVwBryla98JR07dsxBBx2UP/7xj3nxxRdz//3351vf+lb+7//+L0ly0kkn5X/+539yyy235G9/+1u++c1vvu9npHbt2jUDBgzI0UcfnVtuuaV2nzfeeGOSpEuXLqmqqsptt92W6dOnZ968eWndunWGDh2ak08+OePGjcvzzz+fxx9/PD/84Q8zbty4JMnxxx+f5557LqeeemqeffbZXH/99bn22mvX9EsE8IHEKsAass466+SBBx7IJptskv79+6dnz5752te+lrfeeqv2Suspp5ySr371qxkwYEB23nnntG7dOocccsj77veKK67IoYcemm9+85vZfPPN8/Wvfz3z589Pkmy00UYZPnx4Tj/99HTq1CknnHBCkuScc87JWWedlZEjR6Znz57ZZ599cvvtt+dTn/pUkmSTTTbJTTfdlFtuuSXbbLNNxo4dm/POO28NvjoAK6eqsqK7+AEAoIG5sgoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAU6/8DXtYlbl0OaF8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Convert predictions to class indices\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_labels = np.random.randint(0, 10, size=len(predicted_classes))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_cv, predicted_classes)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "class_names = [str(i) for i in range(2)]  \n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"dense_5\" is incompatible with the layer: expected axis -1 of input shape to have value 29, but received input with shape (None, 21)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 21), dtype=float64)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_pred[i]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileyxzczcvl.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"dense_5\" is incompatible with the layer: expected axis -1 of input shape to have value 29, but received input with shape (None, 21)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 21), dtype=float64)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_pred[i]>0.5:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0\n",
    "        \n",
    "y_pred=y_pred.ravel()\n",
    "y_pred=y_pred.astype(int)    \n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ids=list(ids)\n",
    "submit=pd.DataFrame({'PassengerId':ids,'Survived':y_pred})\n",
    "print(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit.to_csv('submit4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('mod.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Survived'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Survived'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(x \u001b[38;5;241m=\u001b[39m [df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSurvived\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m], df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m]], \n\u001b[0;32m      3\u001b[0m          stacked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, color \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m],label \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDead\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare Histogram by Survival\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare ($)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Survived'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[4,3])\n",
    "plt.hist(x = [df[df['Survived']==1]['Fare'], df[df['Survived']==0]['Fare']], \n",
    "         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\n",
    "plt.title('Fare Histogram by Survival')\n",
    "plt.xlabel('Fare ($)')\n",
    "plt.ylabel('# of Passengers')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
